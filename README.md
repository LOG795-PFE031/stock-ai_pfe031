# Guide d'utilisateur pour Stock-AI: PrÃ©diction des prix dâ€™actions en bourse

Bienvenue dans le guide d'utilisateur de notre projet! Ici, vous trouverez une documentation complÃ¨te et dÃ©taillÃ©e sur diffÃ©rents aspects de notre projet.

Tout d'abord, Stock-AI est une plateforme complÃ¨te de prÃ©diction du cours des actions et d'analyse des sentiments utilisant des modÃ¨les d'apprentissage en profondeur (TensorFlow et PyTorch LSTM) et une interface de chatbot alimentÃ©e par l'IA.

## Table des matiÃ¨res

1. [AperÃ§u du projet](#aperÃ§u)
2. [Comment utiliser ce guide](#comment-utiliser-ce-guide-dutilisateur)
3. [Architecture du systÃ¨me](#architecture-du-systÃ¨me)
4. [Installation](#installation)
5. [Rouler le systÃ¨me](#rouler-le-systÃ¨me)
6. [Tester les services](#tester-les-services)
7. [Troubleshooting](#troubleshooting)
8. [FonctionnalitÃ©s](#fonctionnalitÃ©s)
9. [Remerciements](#remerciements)

## Comment utiliser ce guide d'utilisateur

- ğŸ”— **Liens utiles :** Consultez les liens surlignÃ©s en bleu vers d'autres parties du projet, des documents externes ou des ressources pertinentes.
- â‡½ **Retour vers le guide :** Pour retourner Ã  ce guide.

## AperÃ§u 

Le systÃ¨me Stock-AI est une plateforme intÃ©grÃ©e quiÂ :

- PrÃ©dit le cours des actions grÃ¢ce Ã  des modÃ¨les d'apprentissage profond.
- Analyse l'opinion publique pour fournir des informations d'investissement.
- Traite les donnÃ©es via des files d'attente de messages distribuÃ©es.
- Fournit une interface de chatbot interactive pour les requÃªtes des utilisateurs.
- Propose une architecture de microservices pour une Ã©volutivitÃ© et une rÃ©silience optimales.

Le systÃ¨me combine plusieurs technologies, dont PyTorch, TensorFlow, Docker et autres, pour crÃ©er une plateforme complÃ¨te d'analyse boursiÃ¨re.

## Architecture du systÃ¨me

Le systÃ¨me est organisÃ© autour d'une architecture de microservices conteneurisÃ©s avec Docker. Chaque composant est dÃ©diÃ© Ã  une fonction prÃ©cise dans le pipeline d'analyse et de prÃ©diction des marchÃ©s boursiers.

Les services principaux sont :

1. **ğŸ§  Service d'ingestion de donnÃ©es (`data-service`)**  
   RÃ©cupÃ¨re et stocke les donnÃ©es historiques des actions depuis des sources externes dans une base PostgreSQL dÃ©diÃ©e.

2. **ğŸ“° Service d'analyse d'actualitÃ©s (`news-service`)**  
   Collecte les actualitÃ©s financiÃ¨res et effectue une analyse de sentiment via FinBERT.

3. **ğŸ§® Service de prÃ©traitement (`data-processing-service`)**  
   Nettoie, normalise et transforme les donnÃ©es brutes pour les rendre compatibles avec les modÃ¨les d'entraÃ®nement et d'infÃ©rence.

4. **ğŸ‹ï¸â€â™‚ï¸ Service d'entraÃ®nement de modÃ¨les (`training-service`)**  
   EntraÃ®ne des modÃ¨les LSTM, Prophet ou XGBoost Ã  partir des donnÃ©es prÃ©parÃ©es et les enregistre dans MLflow.

5. **ğŸš€ Service de prÃ©diction (`deployment-service`)**  
   Charge les modÃ¨les en production et gÃ©nÃ¨re des prÃ©dictions futures sur les cours boursiers. Fournit Ã©galement les scores de confiance.

6. **ğŸ“ˆ Service dâ€™Ã©valuation (`evaluation-service`)**  
   Compare les prÃ©dictions aux valeurs rÃ©elles et calcule des mÃ©triques comme MAE, RMSE et RÂ².

7. **ğŸ“‰ Service de monitoring (`monitoring-service`)**  
   Surveille les performances des modÃ¨les (drift, erreur, etc.) et dÃ©clenche automatiquement un rÃ©entraÃ®nement si nÃ©cessaire.

8. **ğŸ”€ Service dâ€™orchestration (`orchestration-service`)**  
   Coordonne lâ€™exÃ©cution des workflows de bout en bout (prÃ©traitement â†’ entraÃ®nement â†’ prÃ©diction â†’ Ã©valuation).

9. **ğŸŒ API Gateway (`api-gateway`)**  
   Point dâ€™entrÃ©e unique pour les utilisateurs. Expose toutes les fonctionnalitÃ©s via une interface REST (FastAPI).

10. **ğŸ“Š Services de suivi (`mlflow-server`, `mlflow-postgres`, `mlflow-minio`)**  
    GÃ¨rent le suivi des expÃ©riences ML, le stockage des artefacts, et les mÃ©tadonnÃ©es de modÃ¨les.

11. **âš™ï¸ Services dâ€™automatisation (`prefect-server`, `prefect-postgres`)**  
    UtilisÃ©s pour exÃ©cuter et planifier les workflows Ã  lâ€™aide de Prefect.

Tous les composants sont conteneurisÃ©s avec Docker pour un dÃ©ploiement et une mise Ã  l'Ã©chelle simple.

## Installation

### PrÃ©requis

- Docker et Docker Compose
- Python 3.11+ (pour le dÃ©veloppement local)
- Git

### Ã‰tape 1Â : Configurer le backend
   1. Clonez le dÃ©pÃ´t backend (service C#) Ã  l'adresse https://github.com/LOG795-PFE031/BackendMicroservices_pfe031
   2. Suivez les Ã©tapes du fichier README de ce dÃ©pÃ´t pour le mettre en service.

### Ã‰tape 2Â : Installer le projet

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone <url-du-depot>
   ```

2. Assurez-vous dâ€™Ãªtre Ã  la racine du projet, lÃ  oÃ¹ se trouve le fichier `docker-compose.yml`.

### Ã‰tape 3 : Configurer le Chatbot

CrÃ©ez un fichier `.env` dans le dossier `/chatbot` avec votre clÃ© API OpenAIÂ :
```
OPENAI_API_KEY=your_api_key_here
```
 - *Vous devez avoir une carte de paiement reliÃ©e Ã  votre compte.*

### Ã‰tape 4 : Installer le frontend 
   1. Clonez le dÃ©pÃ´t frontend Ã  l'adresse https://github.com/LOG795-PFE031/NotYahoo_pfe031
   2. Suivez les Ã©tapes du ficher README de ce dÃ©pÃ´t pour le mettre en service.

## Rouler le systÃ¨me

### CrÃ©er et dÃ©marrer les services

Assurez-vous dâ€™Ãªtre Ã  la racine du projet, lÃ  oÃ¹ se trouve le fichier `docker-compose.yml`.

CrÃ©ez et exÃ©cutez tous les services avec Docker ComposeÂ :

```bash
docker compose up --build
```

**Note**: Initial build may take 10-30 minutes as PyTorch and other dependencies are installed.

âš ï¸ Si ce nâ€™est pas votre premier build, supprimez dâ€™abord le dossier `data/` pour Ã©viter les conflits avec dâ€™anciens artefacts : 
   ```bash
   rm -rf data
   docker-compose up --build
   ```

Patientez pendant le lancement, tous les services vont dÃ©marrer automatiquement. Vous pouvez ensuite accÃ©der Ã  lâ€™API sur http://localhost:8000/docs.

### DÃ©marrage de composants individuels

Si vous voulez dÃ©marrer des composants sÃ©parÃ©mentÂ :

**Service d'analyse d'actualitÃ©s**Â :

```bash
docker compose up news-service
```
*MÃªme logique pour les autres services.*

**Chatbot (localement)**Â :

```bash
cd chatbot
python chatbot.py
```

## Tester les services

### Service de prÃ©diction boursiÃ¨re

AccÃ©der Ã  la documentation de l'interface utilisateur Swagger et Ã  l'interface de testÂ :

```
http://localhost:8000/docs
```

Exemples d'appels d'APIÂ :

```bash
curl -X GET "http://localhost:8000/api/predict/AAPL"
```

### Interface du chatbot

Testez le chatbot avec la commande curlÂ :

```bash
curl -X POST http://localhost:5004/chat -H "Content-Type: application/json" -d '{"user_id": "test_user", "query": "Devrais-je investir dans MSFTÂ ?"}'
```

Exemples de requÃªtes pour le chatbotÂ :

- Â«Â Quelle est la prÃ©vision de cours pour AAPLÂ ?Â»
- Â«Â Montrez-moi l'analyse de sentiment pour TeslaÂ Â»
- Â«Â Devrais-je investir dans Google en ce momentÂ ?Â»
- Â«Â Quel est le sentiment de l'actualitÃ© pour NVDAÂ ?Â Â»

## Troubleshooting

### ProblÃ¨mes de clÃ© API du chatbot

Si le chatbot ne parvient pas Ã  se connecter Ã  OpenAIÂ :

1. VÃ©rifiez votre clÃ© API dans le fichier Â«Â .envÂ Â».
2. VÃ©rifiez les limites de dÃ©bit OpenAI ou les modifications de l'API.

## FonctionnalitÃ©s

* **PrÃ©vision boursiÃ¨re multi-modÃ¨les**Â : ModÃ¨les LSTM TensorFlow, PyTorch, Prophet et Xgboost.
* **Chatbot optimisÃ© par l'IA**Â : Interface en langage naturel utilisant OpenAI.
* **Conteneurisation Docker**Â : DÃ©ploiement et mise Ã  l'Ã©chelle faciles.
* **Architecture de microservices**Â : Services indÃ©pendants et faiblement couplÃ©s.

## Remerciements

- OpenAI pour les fonctionnalitÃ©s du chatbot
- yfinance et Stooq pour la fourniture de donnÃ©es boursiÃ¨res
- TensorFlow et PyTorch pour les frameworks d'apprentissage profond
- La communautÃ© open source pour les diffÃ©rents outils et bibliothÃ¨ques

---

## License

[MIT License](LICENSE)
